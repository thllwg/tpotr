input_intermediate[i]=paste0(input[i,],collapse = ",")
}
data=paste0(input_intermediate, collapse =";")
call= paste(base,"/",endpoint,"/",func,"/",token,"/",data,sep="")
#API-Request
data_raw=GET(call)
#extracting content from API response, convert to JSON
data_json=content(data_raw,"text")
#parsing the JSON format
data_json_parsed = fromJSON(data_json, flatten = TRUE)
#Check if error occured
if (names(data_json_parsed)[1]!= "data") {
print(data_json)
return(data_json_parsed)
}
#converting to a data frame
data_df = as.data.frame(data_json_parsed)
#Convert data to string
data_string=as.character(data_df$data)
#Replace '[' and ']'
data_string=gsub("\\[","",data_string)
data_string=gsub("\\]","",data_string)
#Seperate data
split=strsplit(data_string,split=", ")
split=unlist(split)
#convert to double
data=as.double(split)
return (data)
}
base="optim.uni-muenster.de:5000/"
token="777734f87f394dc3a347bafd00db1fb8"
fitness.fun = function(ind){
x = ind[1]
y = ind[2]
z = ind[3]
input = data.frame(x=x, y=y, z=z)
c(apirequest(input, 1, "api-test3D"), apirequest(input, 2, "api-test3D"))
}
MU = 30; LAMBDA = 40; MAX.ITER = 10
ctrl = initECRControl(fitness.fun, n.objectives = 2L, minimize = TRUE)
ctrl = registerECROperator(ctrl, "mutate", mutUniform, lower = c(-5, -5, -5), upper = c(5, 5, 5))
ctrl = registerECROperator(ctrl, "recombine", recCrossover)
ctrl = registerECROperator(ctrl, "selectForMating", selSimple, k = 3L)
ctrl = registerECROperator(ctrl, "selectForSurvival", selNondom)
population = genReal(n = MU, n.dim = 3L, lower = c(-5, -5, -5), upper = c(5, 5, 5))
fitness = evaluateFitness(ctrl, population)
logger = initLogger(ctrl, init.size = MAX.ITER+1, log.pop = TRUE)
updateLogger(logger, population, fitness, n.evals = LAMBDA)
plotFront(fitness)
for(i in seq_len(MAX.ITER)){
offspring = generateOffspring(ctrl, population, fitness, lambda = LAMBDA, p.recomb = 0.7, p.mut = 0.3)
fitness.o = evaluateFitness(ctrl, offspring)
sel = replaceMuPlusLambda(ctrl, population, offspring, fitness, fitness.o)
population = sel$population
fitness = sel$fitness
updateLogger(logger, population, fitness, n.evals = MU)
#plotFront(fitness)
}
updateLogger(logger, population, fitness, n.evals = LAMBDA)
plotFront(fitness)
stats = getStatistics(logger)
plotStatistics(stats)
getPopulations(logger)
#plotScatter2d(, shape = "Species", colour = "Species")
?plotFront
plotFront(fitness, minimize = TRUE)
library("MASS")
library("mlr")
load_all(".")
# The following code illustrates how TPOT can be employed for performing a regression task over the Boston housing prices dataset.
# Running this code should discover a pipeline (exported as tpot_boston_pipeline.py) that achieves at least 10 mean squared error (MSE) on the test set:
data("Boston")
# reproductibility
set.seed(123)
# test_train_split
# 75% of the sample size for training
smp_size <- floor(0.75 * nrow(Boston))
# set the seed to make your partition reproducible
train_ind <- sample(seq_len(nrow(Boston)), size = smp_size)
train <- Boston[train_ind, ]
test <- Boston[-train_ind, ]
# we are using the mlr integration to predict the target variable
task = makeRegrTask(data = Boston, target = "medv")
learner = makeLearner(cl = "regr.tpot", predict.type = "response", id = "BostonHousing", population_size = 10, generations = 2, n_jobs = 3, verbosity = 2)
model = train(learner, task)
pred = predict(obj = model, newdata = test)
performance(pred, measures = list(mse))
# you can gain more insights into how the fitting of the model worked out:
getGenerations(model)
devtools::load_all(".")
library("MASS")
library("mlr")
load_all(".")
# The following code illustrates how TPOT can be employed for performing a regression task over the Boston housing prices dataset.
# Running this code should discover a pipeline (exported as tpot_boston_pipeline.py) that achieves at least 10 mean squared error (MSE) on the test set:
data("Boston")
# reproductibility
set.seed(123)
# test_train_split
# 75% of the sample size for training
smp_size <- floor(0.75 * nrow(Boston))
# set the seed to make your partition reproducible
train_ind <- sample(seq_len(nrow(Boston)), size = smp_size)
train <- Boston[train_ind, ]
test <- Boston[-train_ind, ]
# we are using the mlr integration to predict the target variable
task = makeRegrTask(data = Boston, target = "medv")
learner = makeLearner(cl = "regr.tpot", predict.type = "response", id = "BostonHousing", population_size = 10, generations = 2, n_jobs = 3, verbosity = 2)
model = train(learner, task)
pred = predict(obj = model, newdata = test)
performance(pred, measures = list(mse))
# you can gain more insights into how the fitting of the model worked out:
getGenerations(model)
devtools::use_package("stringr")
devtools::load_all(".")
library("MASS")
library("mlr")
load_all(".")
# The following code illustrates how TPOT can be employed for performing a regression task over the Boston housing prices dataset.
# Running this code should discover a pipeline (exported as tpot_boston_pipeline.py) that achieves at least 10 mean squared error (MSE) on the test set:
data("Boston")
# reproductibility
set.seed(123)
# test_train_split
# 75% of the sample size for training
smp_size <- floor(0.75 * nrow(Boston))
# set the seed to make your partition reproducible
train_ind <- sample(seq_len(nrow(Boston)), size = smp_size)
train <- Boston[train_ind, ]
test <- Boston[-train_ind, ]
# we are using the mlr integration to predict the target variable
task = makeRegrTask(data = Boston, target = "medv")
learner = makeLearner(cl = "regr.tpot", predict.type = "response", id = "BostonHousing", population_size = 10, generations = 2, n_jobs = 3, verbosity = 2)
model = train(learner, task)
pred = predict(obj = model, newdata = test)
performance(pred, measures = list(mse))
# you can gain more insights into how the fitting of the model worked out:
getGenerations(model)
install.packages("stringr")
class(learner)
class(model)
class(mod)
performance(pred, measures = list(acc))
performance(pred, measures = list(mse))
is.numeric(performance(pred, measures = list(mse)))
model$learner.model$TPOTObject$fitted_pipeline_
data(iris)
## set the seed to make your partition reproducible
set.seed(123)
## 75% of the sample size
smp_size <- floor(0.75 * nrow(iris))
train_ind <- sample(seq_len(nrow(iris)), size = smp_size)
train <- iris[train_ind, ]
test <- iris[-train_ind, ]
train.features <- train[1:4]
train.classes <- as.numeric(train[[5]])#as.factor(train[[5]])
test.features <- test[1:4]
test.classes <- as.numeric(test[[5]])#as.factor(test[[5]])
tpot <- TPOTRClassifier(verbosity=2, max_time_mins=1, max_eval_time_mins=0.04, population_size=15)
expect_true(BBmisc::isSubset(c("TPOTRClassifier"), class(tpot)))
expect_true(BBmisc::isSubset(c("tpot.tpot.TPOTClassifier", "tpot.base.TPOTBase", "sklearn.base.BaseEstimator", "python.builtin.object"), class(tpot$TPOTObject)))
tpot <- fit(tpot, train.features, train.classes)
p <- predict(c, test.features)
p <- predict(tpot, test.features)
p
class(p)
is.numeric(p)
s <- score(tpot, test.features, test.classes)
s
devtools::load_all(".")
devtools::check()
devtools::check()
devtools::load_all(".")
devtools::check()
test_check("tpotr")
test_check("tpotr")
devtools::load_all(".")
devtools::check()
runif(100, -5, 5)
df = data.frame(x = runif(100000, -5, 5), y = runif(100000, -5, 5), z = runif(100000, -5, 5))
head(df)
?by
?tapply
nrow(df)
nrow(df)%50
nrow(df)/50
for (i in c(0:(nrow(df)/50)){
print(i)
}
for (i in c(0:(nrow(df)/50))){
print(i)
}
df[,1:50]
df[1:50,]
2000/50
10000/50
nrow(df)
nrow(df)/50
seq(1, nrow(df), 50)
df[1:50,]
df[1:50,]$target = 12
df[1:50,4] = 12
df[1:50,] = 12
df[1:50,]
df = data.frame(x = runif(100000, -5, 5), y = runif(100000, -5, 5), z = runif(100000, -5, 5))
df[1:50,]
df[1:50,4] = 12
df[1:50,]
df = data.frame(x = runif(100000, -5, 5), y = runif(100000, -5, 5), z = runif(100000, -5, 5))
df[1:50,]$"target"
df[1:50,]$"target" = 12
df[1:50,"target"] = 12
df[1:50,]
return = apirequest(df[1:50,],1,"api-test3D")
if (!require("httr")) library(httr)
if (!require("jsonlite")) library(jsonlite)
apirequest = function(input, func, endpoint){
if(endpoint=="api"){
return("Access denied! :)")
}
input_intermediate = 1:nrow(input)
for(i in 1:nrow(input)){
input_intermediate[i]=paste0(input[i,],collapse = ",")
}
data=paste0(input_intermediate, collapse =";")
call= paste(base,"/",endpoint,"/",func,"/",token,"/",data,sep="")
#API-Request
data_raw=GET(call)
#extracting content from API response, convert to JSON
data_json=content(data_raw,"text")
#parsing the JSON format
data_json_parsed = fromJSON(data_json, flatten = TRUE)
#Check if error occured
if (names(data_json_parsed)[1]!= "data") {
print(data_json)
return(data_json_parsed)
}
#converting to a data frame
data_df = as.data.frame(data_json_parsed)
#Convert data to string
data_string=as.character(data_df$data)
#Replace '[' and ']'
data_string=gsub("\\[","",data_string)
data_string=gsub("\\]","",data_string)
#Seperate data
split=strsplit(data_string,split=", ")
split=unlist(split)
#convert to double
data=as.double(split)
return (data)
}
base="optim.uni-muenster.de:5000/"
token="777734f87f394dc3a347bafd00db1fb8"
return = apirequest(df[1:50,],1,"api-test3D")
df[1:50,]
df = data.frame(x = runif(100000, -5, 5), y = runif(100000, -5, 5), z = runif(100000, -5, 5))
df[1:50,]
return = apirequest(df[1:50,],1,"api-test3D")
return
df[1:50,"f1"] = return
df[1:50,]
for (i in seq(1,(nrow(df), 50))){
df[i:(i+49),"f1"] = apirequest(df[i:(i+49),],1,"api-test3D")
df[i:(i+49),"f2"] = apirequest(df[i:(i+49),],2,"api-test3D")
}
seq(1,nrow(df),50)
df = data.frame(x = runif(100000, -5, 5), y = runif(100000, -5, 5), z = runif(100000, -5, 5))
for (i in seq(1,nrow(df), 50)){
df[i:(i+49),"f1"] = apirequest(df[i:(i+49),],1,"api-test3D")
df[i:(i+49),"f2"] = apirequest(df[i:(i+49),],2,"api-test3D")
}
df = data.frame(x = runif(100000, -5, 5), y = runif(100000, -5, 5), z = runif(100000, -5, 5))
i = 1
df[i:(i+49),"f1"] = apirequest(df[i:(i+49),],1,"api-test3D")
df[i:(i+49),"f2"] = apirequest(df[i:(i+49),],2,"api-test3D")
df = data.frame(x = runif(100000, -5, 5), y = runif(100000, -5, 5), z = runif(100000, -5, 5))
for (i in seq(1,nrow(df), 50)){
df[i:(i+49),"f1"] = apirequest(df[i:(i+49),1:3],1,"api-test3D")
df[i:(i+49),"f2"] = apirequest(df[i:(i+49),1:3],2,"api-test3D")
}
head(df)
write.csv(df, file = "test3D.csv", sep = ",")
#Preprocessing
data <- read.csv(url("https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data"), header = FALSE)
colnames(data) <- c('Sample code number', 'Clump Thickness','Uniformity of Cell Size','Uniformity of Cell Shape','Marginal Adhesion','Single Epithelial Cell Size','Bare Nuclei','Bland Chromatin','Normal Nucleoli','Mitoses','Class')
missing <- (apply(data, 1, function(x){any(x == "?")}))
data <- data[!missing,]
data$"Bare Nuclei" <- as.integer(as.character(data$"Bare Nuclei"))
data <- data[,c(2:11)]
heaed(data)
head(data)
dim(data)
grep("^Species$", colnames(iris))
model$task.desc$target
paste0("^", model$task.desc$target, "$"
paste0("^", model$task.desc$target, "$")
devtools::load_all(".")
library("mlr")
data(iris)
# 75% of the sample size
smp_size <- floor(0.75 * nrow(iris))
# set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(iris)), size = smp_size)
train <- iris[train_ind, ]
test <- iris[-train_ind, ]
train[5] <- as.factor(as.numeric(train[[5]]))
test[5] <- as.factor(as.numeric(test[[5]]))
task = makeClassifTask(data = train, target = "Species", id = "iris")
learner = makeLearner(cl = "classif.tpot", population_size = 10, generations = 3, n_jobs = 3, verbosity = 2)
model = train(learner, task)
pred = predict(obj = model, newdata = test)
print(pred)
performance(pred, measures = list(acc))
library(caTools)
#REGRESSION1 - EXAMPLE2
data_wine <- read.csv(url("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv"), header = TRUE, sep=";")
data_wine$"quality" <- as.numeric(as.character(data_wine$"quality"))
#Training-Test Split
set.seed(101)
sample_wine = sample.split(data_wine$`fixed.acidity`, SplitRatio = 2/3)
train_wine = subset(data_wine, sample_wine == TRUE)
train_wine.features = train_wine[,1:11]
train_wine.classes = train_wine[,12]
test_wine  = subset(data_wine, sample_wine == FALSE)
test_wine.features = test_wine[,1:11]
test_wine.classes = test_wine[,12]
task.regr = makeRegrTask(data = train_wine, target = "quality", id = "wine.regr")
learner.regr = makeLearner(cl = "regr.tpot", population_size = 50, generations = 11, n_jobs = 3, verbosity = 2)
model.regr = train(learner.regr, task.regr)
predict(obj = model.regr, newdata = test_wine.features)
?makeUntypedLearnerParam
devtools::load_all(".")
library("mlr")
data(iris)
# 75% of the sample size
smp_size <- floor(0.75 * nrow(iris))
# set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(iris)), size = smp_size)
train <- iris[train_ind, ]
test <- iris[-train_ind, ]
train[5] <- as.factor(as.numeric(train[[5]]))
test[5] <- as.factor(as.numeric(test[[5]]))
task = makeClassifTask(data = train, target = "Species", id = "iris")
learner = makeLearner(cl = "classif.tpot", population_size = 10, generations = 3, n_jobs = 3, verbosity = 2)
model = train(learner, task)
pred = predict(obj = model, newdata = test)
performance(pred, measures = list(acc))
pred
pred$data
pred = predict(obj = model, newdata = test)
performance(pred, measures = list(acc))
learner = makeLearner(cl = "classif.tpot", population_size = 10, generations = 3, n_jobs = 3, verbosity = 2, config_dict = "TPOT light")
model = train(learner, task)
pred = predict(obj = model, newdata = test)
performance(pred, measures = list(acc))
devtools::load_all(".")
library("mlr")
data(iris)
# 75% of the sample size
smp_size <- floor(0.75 * nrow(iris))
# set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(iris)), size = smp_size)
train <- iris[train_ind, ]
test <- iris[-train_ind, ]
train[5] <- as.factor(as.numeric(train[[5]]))
test[5] <- as.factor(as.numeric(test[[5]]))
task = makeClassifTask(data = train, target = "Species", id = "iris")
learner = makeLearner(cl = "classif.tpot", population_size = 10, generations = 3, n_jobs = 3, verbosity = 2, config_dict = "TPOT light")
model = train(learner, task)
pred = predict(obj = model, newdata = test)
performance(pred, measures = list(acc))
library("mlr")
data(iris)
# 75% of the sample size
smp_size <- floor(0.75 * nrow(iris))
# set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(iris)), size = smp_size)
train <- iris[train_ind, ]
test <- iris[-train_ind, ]
train[5] <- as.factor(as.numeric(train[[5]]))
test[5] <- as.factor(as.numeric(test[[5]]))
task = makeClassifTask(data = train, target = "Species", id = "iris")
learner = makeLearner(cl = "classif.tpot", population_size = 10, generations = 6, n_jobs = 3, verbosity = 2, config_dict = "TPOT light")
model = train(learner, task)
pred = predict(obj = model, newdata = test)
performance(pred, measures = list(acc))
library("mlr")
data(iris)
# 75% of the sample size
smp_size <- floor(0.75 * nrow(iris))
# set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(iris)), size = smp_size)
train <- iris[train_ind, ]
test <- iris[-train_ind, ]
train[5] <- as.factor(as.numeric(train[[5]]))
test[5] <- as.factor(as.numeric(test[[5]]))
task = makeClassifTask(data = train, target = "Species", id = "iris")
learner = makeLearner(cl = "classif.tpot", population_size = 10, generations = 20, n_jobs = 3, verbosity = 2, config_dict = "TPOT light")
model = train(learner, task)
pred = predict(obj = model, newdata = test)
performance(pred, measures = list(acc))
library("mlr")
data(iris)
# 75% of the sample size
smp_size <- floor(0.75 * nrow(iris))
# set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(iris)), size = smp_size)
train <- iris[train_ind, ]
test <- iris[-train_ind, ]
train[5] <- as.factor(as.numeric(train[[5]]))
test[5] <- as.factor(as.numeric(test[[5]]))
task = makeClassifTask(data = train, target = "Species", id = "iris")
learner = makeLearner(cl = "classif.tpot", population_size = 20, generations = 20, n_jobs = 3, verbosity = 2, config_dict = "TPOT light")
model = train(learner, task)
pred = predict(obj = model, newdata = test)
performance(pred, measures = list(acc))
printPipeline(model)
predict(obj = model, newdata = iris)
predict(obj = model, newdata = rbind(train,test))
pred = predict(obj = model, newdata = rbind(train,test))
performance(pred, measures = list(acc))
?conda_binary
conda_list(conda)
reticulate::conda_list
reticulate::conda_list(conda)
reticulate::conda_list("conda")
reticulate::conda_list()
devtools::use_package("microbenchmark")
devtools::load_all(".")
library("mlr")
data(iris)
# 75% of the sample size
smp_size <- floor(0.75 * nrow(iris))
# set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(iris)), size = smp_size)
train <- iris[train_ind, ]
test <- iris[-train_ind, ]
train[5] <- as.factor(as.numeric(train[[5]]))
test[5] <- as.factor(as.numeric(test[[5]]))
task = makeClassifTask(data = train, target = "Species", id = "iris")
learner = makeLearner(cl = "classif.tpot", population_size = 10, generations = 3, n_jobs = 3, verbosity = 2)
model = train(learner, task)
pred = predict(obj = model, newdata = test)
print(pred)
performance(pred, measures = list(acc))
printPipeline(model)
library(mlbench)
data("Glass")
str(Glass)
library(mlr)
library(mlbench)
library(mlr)
data("Glass")
## 75% of the sample size
smp_size <- floor(0.75 * nrow(Glass))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(Glass)), size = smp_size)
train <- Glass[train_ind, ]
test <- Glass[-train_ind, ]
task = makeClassifTask(data = train, target = "Type", id = "Glass")
lrn = makeLearner(cl = "classif.tpot", generations = 20, population_size = 20, n_jobs = 4, config_dict = "TPOT light")
model = train(lrn, task)
pred = predict(model, newdata = test)
performance(pred, measure = list(acc))
devtools::load_all(".")
library(mlbench)
library(mlr)
data("Glass")
## 75% of the sample size
smp_size <- floor(0.75 * nrow(Glass))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(Glass)), size = smp_size)
train <- Glass[train_ind, ]
test <- Glass[-train_ind, ]
task = makeClassifTask(data = train, target = "Type", id = "Glass")
lrn = makeLearner(cl = "classif.tpot", generations = 20, population_size = 20, n_jobs = 4, config_dict = "TPOT light")
model = train(lrn, task)
pred = predict(model, newdata = test)
performance(pred, measure = list(acc))
pred
lrn = makeLearner(cl = "classif.tpot", generations = 20, population_size = 20, n_jobs = 4, config_dict = "TPOT light", verbosity = 2)
model = train(lrn, task)
pred = predict(model, newdata = test)
performance(pred, measure = list(acc))
lrn = makeLearner(cl = "classif.tpot", generations = 20, population_size = 20, n_jobs = 4, verbosity = 2)
model = train(lrn, task)
pred = predict(model, newdata = test)
performance(pred, measure = list(acc))
lrn = makeLearner(cl = "classif.tpot", generations = 20, population_size = 30, n_jobs = 4, verbosity = 2)
model = train(lrn, task)
pred = predict(model, newdata = test)
performance(pred, measure = list(acc))
lrn = makeLearner(cl = "classif.tpot", generations = 30, population_size = 20, n_jobs = 6, verbosity = 2)
model = train(lrn, task)
pred = predict(model, newdata = test)
performance(pred, measure = list(acc))
pred = predict(model, newdata = test)
performance(pred, measure = list(acc))
lrn = makeLearner(cl = "classif.tpot", generations = 40, population_size = 10, n_jobs = 6, verbosity = 2)
model = train(lrn, task)
pred = predict(model, newdata = test)
performance(pred, measure = list(acc))
printPipeline(model)
